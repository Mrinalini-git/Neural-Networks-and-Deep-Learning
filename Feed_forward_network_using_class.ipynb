{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e4usN83AVz_",
        "outputId": "78a9ee22-be5c-4546-fde4-6a7b74eacc15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Initial Parameters ---\n",
            "\n",
            "Initial Weights:\n",
            " [[0.2 0.1]\n",
            " [0.3 0.5]\n",
            " [0.6 0.4]]\n",
            "\n",
            "Initial Biases: [0.1 0.2]\n",
            "\n",
            "--- Training for one iteration with learning rate = 0.1 ---\n",
            "\n",
            "Forward propagation completed!\n",
            "Activated Output: [0.60825903 0.61538376]\n",
            "\n",
            "Mean Squared Error (MSE):\n",
            "0.005978338849438986\n",
            "\n",
            "Backward propagation completed!\n",
            "\n",
            "Gradients for weights (dw):\n",
            "[[0.01289798 0.00182056]\n",
            " [0.00515919 0.00072823]\n",
            " [0.00773879 0.00109234]]\n",
            "\n",
            "Gradients for biases (db):\n",
            "0.029437088748521897\n",
            "\n",
            "Parameters updated successfully!\n",
            "\n",
            "Updated Weights: [[0.1987102  0.09981794]\n",
            " [0.29948408 0.49992718]\n",
            " [0.59922612 0.39989077]]\n",
            "\n",
            "Updated Biases: [0.09705629 0.19705629]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, w, b, x, y_target):\n",
        "        self.w = w\n",
        "        self.b = b\n",
        "        self.x = x\n",
        "        self.y_target = y_target\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def forward(self):\n",
        "        self.Z = np.dot(self.x, self.w) + self.b\n",
        "        self.A = self.sigmoid(self.Z)\n",
        "        print(\"\\nForward propagation completed!\")\n",
        "        print(\"Activated Output:\", self.A)\n",
        "\n",
        "    def calculate_loss(self):\n",
        "        self.loss = np.mean((self.A - self.y_target)**2)\n",
        "        print(\"\\nMean Squared Error (MSE):\")\n",
        "        print(self.loss)\n",
        "\n",
        "    def backward(self):\n",
        "        dA = 2 * (self.A - self.y_target) / self.y_target.size\n",
        "        self.dZ = dA * self.sigmoid_derivative(self.A)\n",
        "        # Fixed: Using np.outer to correctly calculate dw for a single input sample\n",
        "        self.dw = np.outer(self.x, self.dZ)\n",
        "        self.db = np.sum(self.dZ, axis=0)\n",
        "        print(\"\\nBackward propagation completed!\")\n",
        "        print(\"\\nGradients for weights (dw):\")\n",
        "        print(self.dw)\n",
        "        print(\"\\nGradients for biases (db):\")\n",
        "        print(self.db)\n",
        "\n",
        "    def train(self, learning_rate):\n",
        "        self.forward()\n",
        "        self.calculate_loss()\n",
        "        self.backward()\n",
        "        self.w -= learning_rate * self.dw\n",
        "        self.b -= learning_rate * self.db\n",
        "        print(\"\\nParameters updated successfully!\")\n",
        "        print(\"\\nUpdated Weights:\", self.w)\n",
        "        print(\"\\nUpdated Biases:\", self.b)\n",
        "\n",
        "# Move these definitions outside the train method and ensure correct indentation\n",
        "initial_w = np.array([[0.2, 0.1], [0.3, 0.5] , [0.6, 0.4]])\n",
        "initial_b = np.array([0.1, 0.2])\n",
        "x_input = np.array([0.5, 0.2, 0.3])\n",
        "y_target_output = np.array([0.5, 0.6])\n",
        "\n",
        "# Instantiate the NeuralNetwork\n",
        "nn = NeuralNetwork(initial_w, initial_b, x_input, y_target_output)\n",
        "\n",
        "print(\"\\n--- Initial Parameters ---\")\n",
        "print(\"\\nInitial Weights:\\n\", nn.w)\n",
        "print(\"\\nInitial Biases:\", nn.b)\n",
        "\n",
        "# Train for one iteration\n",
        "learning_rate = 0.1\n",
        "print(f\"\\n--- Training for one iteration with learning rate = {learning_rate} ---\")\n",
        "nn.train(learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oUVoXRDHAY56"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}